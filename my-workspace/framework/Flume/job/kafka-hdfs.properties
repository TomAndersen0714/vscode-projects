# 此配置文件主要用于将Kafka中的启动日志和用户行为数据输出到HDFS中
# Kafka Channel->HDFS Sink

# Agent
a1.channels = c1 c2
a1.sinks = k1 k2

# Channels.c1
# 设置a1.channels.c1的类型
a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
# 设置Kafka集群中的Broker
a1.channels.c1.kafka.bootstrap.servers = kafkaServer1:9092,kafkaServer2:9092,kafkaServer3:9092
# 设置a1.channels.c1使用的Kafka的Topic
a1.channels.c1.kafka.topic = topic_start
# 设置成不按照flume event格式解析数据,因为同一个Kafka topic可能有非flume Event类数据传入
a1.channels.c1.parseAsFlumeEvent = false
# 设置消费者组,保证每次消费时能够获取上次对应的Offset
a1.channels.c1.kafka.consumer.group.id = flume-consumer-group
# 设置消费过程poll()超时时间(ms)
a1.channels.c1.pollTimeout = 1000

# Channels.c2
# 设置a1.channels.c2的类型
a1.channels.c2.type = org.apache.flume.channel.kafka.KafkaChannel
# 设置Kafka集群中的Broker
a1.channels.c2.kafka.bootstrap.servers = kafkaServer1:9092,kafkaServer2:9092,kafkaServer3:9092
# 设置a1.channels.c2使用的Kafka的Topic
a1.channels.c2.kafka.topic = topic_event
# 设置成不按照flume event格式解析数据,因为同一个Kafka topic可能有非flume Event类数据传入
a1.channels.c2.parseAsFlumeEvent = false
# 设置消费者组,保证每次消费时能够获取上次对应的Offset
a1.channels.c2.kafka.consumer.group.id = flume-consumer-group
# 设置消费过程poll超时时间(ms)
a1.channels.c2.pollTimeout = 1000

# Sinks.k1
# 配置HDFS Sink
a1.sinks.k1.type = hdfs
# 设置hdfs文件路径,同时并设置了按照日期创建文件夹(存储启动日志)
a1.sinks.k1.hdfs.path = /logs/app_start/%Y-%m-%d/%H-%M-%S
# 设置flume创建的hdfs文件前缀(表示启动日志)
a1.sinks.k1.hdfs.filePrefix = start-logs

# 以下三组参数的配置用于控制flume在hdfs中生成文件的滚动方式
# 满足以下三者中任何一个条件都会新生成hdfs文件
# 设置文件滚动的时间间隔,单位(second),置0表示关闭
a1.sinks.k1.hdfs.rollInterval = 10
# 设置文件滚动的最大size阈值,由于是hdfs sink故最好设置成Block Size的倍数
# 本次实验的hadoop版本为2.7.7(2.7.3之后默认Block Size为128MB,之前为64MB)
# 单位(bytes),置0表示关闭
a1.sinks.k1.hdfs.rollSize = 134217700
# 设置滚动文件存储的最大Event个数
# 此参数一般设置为0,即关闭,除非有严格生产需求并且知道Event大小能够自主控制
a1.sinks.k1.hdfs.rollCount = 0

# 设置flume每批次刷到hdfs中的Event个数(超过一定时长也会进行刷新,并非要等满一批次)
a1.sinks.k1.hdfs.batchSize = 100

# 设置hdfs文件格式,目前只支持(SequenceFile/DataStream/CompressedStream)
# 其中CompressedStream类型需要配合hdfs.codeC参数来指定具体的压缩方式
# SequenceFile表示按照序列文件的方式进行压缩,而DataStream则表示不进行压缩
# 此处使用lz4压缩算法对日志文件进行压缩存储到hdfs中,需要保证主机拥有lz4库
# 使用hadoop checknative命令可以查看是否具有对应压缩算法本地库
a1.sinks.k1.hdfs.fileType = CompressedStream
a1.sinks.k1.hdfs.codeC = org.apache.hadoop.io.compress.Lz4Codec

# 以下三组参数的配置配合转义序列(如%y %m %d %H %M %S等)能够自定义时间轮转最小刻度
# 设置hdfs时间四舍五入,四舍五入的界限为(roundValue*roundUnit),本次设置的以30s为界限
# 注:通常理解的四舍五入以5为界限
# 设置四舍五入之后文件夹将按照一定时间大小的刻度进行创建文件夹
# 否则都是按照之前设置每分钟进行文件夹的创建
a1.sinks.k1.hdfs.round = true
# 设置hdfs时间四舍五入的最小单元倍数
a1.sinks.k1.hdfs.roundValue = 30
# 设置hdfs时间四舍五入的最小单位
a1.sinks.k1.hdfs.roundUnit = second

# 设定是否使用本地时间戳,默认为false,即使用Event的Header中的时间戳,但本次实验中Event-Header为空
a1.sinks.k1.hdfs.useLocalTimeStamp = true

# Sinks.k2
# 配置HDFS Sink
a1.sinks.k2.type = hdfs
# 设置hdfs文件路径,同时并设置了按照日期创建文件夹(存储事件日志)
a1.sinks.k2.hdfs.path = /logs/app_event/%Y-%m-%d/%H-%M-%S
# 设置flume创建的hdfs文件前缀(表示事件日志)
a1.sinks.k2.hdfs.filePrefix = event-logs

# 以下三组参数的配置用于控制flume在hdfs中生成文件的滚动方式
# 满足以下三者中任何一个条件都会新生成hdfs文件
# 设置文件滚动的时间间隔,单位(second),置0表示关闭
a1.sinks.k2.hdfs.rollInterval = 10
# 设置文件滚动的最大size阈值,由于是hdfs sink故最好设置成Block Size的倍数
# 本次实验的hadoop版本为2.7.7(2.7.3之后默认Block Size为128MB,之前为64MB)
# 单位(bytes),置0表示关闭
a1.sinks.k2.hdfs.rollSize = 134217700
# 设置滚动文件存储的最大Event个数
# 此参数一般设置为0,即关闭,除非有严格生产需求并且知道Event大小能够自主控制
a1.sinks.k2.hdfs.rollCount = 0

# 设置flume每批次刷到hdfs中的Event个数(超过一定时长也会进行刷新,并非要等满一批次)
a1.sinks.k2.hdfs.batchSize = 100

# 设置hdfs文件格式,目前只支持(SequenceFile/DataStream/CompressedStream)
# 其中CompressedStream类型需要配合hdfs.codeC参数来指定具体的压缩方式
# SequenceFile表示按照序列文件的方式进行压缩,而DataStream则表示不进行压缩
# 此处使用lz4压缩算法对日志文件进行压缩存储到hdfs中,需要保证主机拥有lz4库
# 使用hadoop checknative命令可以查看是否具有对应压缩算法本地库
a1.sinks.k2.hdfs.fileType = CompressedStream
a1.sinks.k2.hdfs.codeC = org.apache.hadoop.io.compress.Lz4Codec

# 以下三组参数的配置配合转义序列(如%y %m %d %H %M %S等)能够自定义时间轮转最小刻度
# 设置hdfs时间四舍五入,四舍五入的界限为(roundValue*roundUnit),本次设置的以30s为界限
# 注:通常理解的四舍五入以5为界限
# 设置四舍五入之后文件夹将按照一定时间大小的刻度进行创建文件夹
# 否则都是按照之前设置每分钟进行文件夹的创建
a1.sinks.k2.hdfs.round = true
# 设置hdfs时间四舍五入的最小单元倍数
a1.sinks.k2.hdfs.roundValue = 30
# 设置hdfs时间四舍五入的最小单位
a1.sinks.k2.hdfs.roundUnit = second

# 设定是否使用本地时间戳,默认为false,即使用Event的Header中的时间戳,但本次实验中Event-Header为空
a1.sinks.k2.hdfs.useLocalTimeStamp = true

# Binding
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2
