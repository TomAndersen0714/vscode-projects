# 用于从netcat指定端口收集数据最终输出到HDFS中

# Agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Sources
# a1.sources.r1
# 配置source类型/绑定主机ip/端口号
a1.sources.r1.type = netcat
a1.sources.r1.bind = 0.0.0.0
a1.sources.r1.port = 44444

# Sinks
# a1.sinks.k1
a1.sinks.k1.type = hdfs
# 设置hdfs文件路径,同时并设置了按照日期创建文件夹
a1.sinks.k1.hdfs.path = /flume/logs/%Y-%m-%d/%H-%M-%S
# 设置flume创建的hdfs文件前缀
a1.sinks.k1.hdfs.filePrefix = logs_%Y-%m-%d

# 以下三组参数的配置用于控制flume在hdfs中生成文件的滚动方式
# 满足以下三者中任何一个条件都会新生成hdfs文件
# 设置文件滚动的时间间隔,单位(second),置0表示关闭
a1.sinks.k1.hdfs.rollInterval = 10
# 设置文件滚动的最大size阈值,由于是hdfs sink故最好设置成Block Size的倍数
# 本次实验的hadoop版本为2.7.7(2.7.3之后默认Block Size为128MB,之前为64MB)
# 单位(bytes),置0表示关闭
a1.sinks.k1.hdfs.rollSize = 134217700
# 设置滚动文件存储的最大Event个数
# 此参数一般设置为0,即关闭,除非有严格生产需求并且知道Event大小能够自主控制
a1.sinks.k1.hdfs.rollCount = 0

# 设置flume每批次刷到hdfs中的Event个数(超过一定时长也会进行刷新,并非要等满一批次)
a1.sinks.k1.hdfs.batchSize = 100

# 设置hdfs文件格式,目前只支持(SequenceFile/DataStream/CompressedStream)
# CompressedStream类型需要配合hdfs.codeC参数来指定具体的压缩方式
# SequenceFile表示按照HDFS序列文件SequenceFile的方式进行压缩
# DataStream则表示不进行压缩
a1.sinks.k1.hdfs.fileType = DataStream

# 以下三组参数的配置配合转义序列(如%y %m %d %H %M %S等)能够自定义时间轮转最小刻度
# 设置hdfs时间向下取整
# 设置向下取整之后文件夹将按照一定时间大小的刻度进行创建文件夹
# 否则都是按照之前设置每分钟进行文件夹的创建
a1.sinks.k1.hdfs.round = true
# 设置hdfs时间向下取整的最小单元倍数
a1.sinks.k1.hdfs.roundValue = 30
# 设置hdfs时间向下取整的最小单位
a1.sinks.k1.hdfs.roundUnit = second

# 设定是否使用本地时间戳,默认为false(即使用Event的Header中的时间戳)
# 本次实验中Event的Header为空,需要使用本地时间戳
a1.sinks.k1.hdfs.useLocalTimeStamp = true


# Channels
# 定义a2的channerls.c1的类型为memory,即使用内存作为缓存/最多缓存的Event个数/单次传输的Event个数
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100


# 绑定Sources/Sinks到Channels上
# 注意:source可以绑定多个channel,但是sink只能绑定单个channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1