<?xml version="1.0"?>
<!--
       NOTE: User and query level settings are set up in "users.xml" file.
-->
<yandex>
    <macros>
        <layer>01</layer>
        <shard>01</shard>
        <replica>cluster01-01-01</replica>
    </macros>
    <http_port>8123</http_port>
    <tcp_port>9000</tcp_port>
    <interserver_http_port>9009</interserver_http_port>

    <max_server_memory_usage_to_ram_ratio>0.8</max_server_memory_usage_to_ram_ratio>

    <listen_host>0.0.0.0</listen_host>

    <logger>
        <!-- Possible levels: https://github.com/pocoproject/poco/blob/poco-1.9.4-release/Foundation/include/Poco/Logger.h#L105 -->
        <level>trace</level>
        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
        <size>1000M</size>
        <count>10</count>
        <!-- <console>1</console> -->        <!-- Default behavior is autodetection (log to console if not daemon mode and is tty) -->
    </logger>
    <!--display_name>production</display_name-->    <!-- It is the name that will be shown in the client -->

    <mysql_port>9004</mysql_port>


    <max_connections>4096</max_connections>
    <keep_alive_timeout>3</keep_alive_timeout>

    <!-- Maximum number of concurrent queries. -->
    <max_concurrent_queries>100</max_concurrent_queries>

    <max_server_memory_usage>0</max_server_memory_usage>

    <total_memory_profiler_step>4194304</total_memory_profiler_step>

    <uncompressed_cache_size>8589934592</uncompressed_cache_size>

    <!-- Approximate size of mark cache, used in tables of MergeTree family.
                  In bytes. Cache is single for server. Memory is allocated only on demand.
         You should not lower this value.
      -->
    <mark_cache_size>5368709120</mark_cache_size>


    <!-- Path to data directory, with trailing slash. -->
    <path>/var/lib/clickhouse/</path>

    <!-- Path to temporary data for processing hard queries. -->
    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>

    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>

    <!-- Path to folder where users and roles created by SQL commands are stored. -->
    <access_control_path>/var/lib/clickhouse/access/</access_control_path>

    <!-- Path to configuration file with users, access rights, profiles of settings, quotas. -->
    <users_config>users.xml</users_config>

    <!-- Default profile of settings. -->
    <default_profile>default</default_profile>

    <default_database>default</default_database>
    <max_threads>8</max_threads>
    <timezone>Asia/Shanghai</timezone>

    <mlock_executable>false</mlock_executable>

    <!-- Configuration of clusters that could be used in Distributed tables.
                  https://clickhouse.tech/docs/en/operations/table_engines/distributed/
      -->
    <remote_servers >
        <cluster_1s_1r>
            <!-- 数据分片1  -->
            <shard>
                <replica>
                    <host>10.0.0.9</host>
                    <port>9900</port>
                </replica>
            </shard>
        </cluster_1s_1r>



    </remote_servers>
    <!-- 存储策略 -->
    <storage_configuration>
        <disks>
            <data1>
                <path>/etc/data1/</path>
                <keep_free_space_bytes>1073741824</keep_free_space_bytes>
            </data1>
            <data2>
                <path>/etc/data2/</path>
                <keep_free_space_bytes>1073741824</keep_free_space_bytes>
            </data2>
            <data3>
                <path>/etc/data3/</path>
                <keep_free_space_bytes>1073741824</keep_free_space_bytes>
            </data3>
            <data4>
                <path>/etc/data4/</path>
                <keep_free_space_bytes>1073741824</keep_free_space_bytes>
            </data4>
        </disks>

        <policies>
            <rr>
                <volumes>
                    <single>
                        <disk>data1</disk>
                        <disk>data2</disk>
                        <disk>data3</disk>
                        <disk>data4</disk>
                    </single>
                </volumes>
            </rr>

        </policies>
    </storage_configuration>

    <!-- The list of hosts allowed to use in URL-related storage engines and table functions.
                 If this section is not present in configuration, all hosts are allowed.
    -->
    <remote_url_allow_hosts>

    </remote_url_allow_hosts>



    <zookeeper incl="zookeeper-servers" optional="true" />

    <!-- Substitutions for parameters of replicated tables.
                   Optional. If you don't use replicated tables, you could omit that.

         See https://clickhouse.yandex/docs/en/table_engines/replication/#creating-replicated-tables
      -->
    <macros incl="macros" optional="true" />


    <!-- Reloading interval for embedded dictionaries, in seconds. Default: 3600. -->
    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>


    <!-- Maximum session timeout, in seconds. Default: 3600. -->
    <max_session_timeout>3600</max_session_timeout>

    <!-- Default session timeout, in seconds. Default: 60. -->
    <default_session_timeout>60</default_session_timeout>


    <!-- Query log. Used only for queries with setting log_queries = 1. -->
    <query_log>
        <!-- What table to insert data. If table is not exist, it will be created.
                          When query log structure is changed after system update,
              then old table will be renamed and new table will be created automatically.
        -->
        <database>system</database>
        <table>query_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>

        <!-- Instead of partition_by, you can provide full engine expression (starting with ENGINE = ) with parameters,
                          Example: <engine>ENGINE = MergeTree PARTITION BY toYYYYMM(event_date) ORDER BY (event_date, event_time) SETTINGS index_granularity = 1024</engine>
          -->

        <!-- Interval of flushing data. -->
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </query_log>

    <!-- Trace log. Stores stack traces collected by query profilers.
                  See query_profiler_real_time_period_ns and query_profiler_cpu_time_period_ns settings. -->
    <trace_log>
        <database>system</database>
        <table>trace_log</table>

        <partition_by>toYYYYMM(event_date)</partition_by>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </trace_log>

    <!-- Query thread log. Has information about all threads participated in query execution.
                  Used only for queries with setting log_query_threads = 1. -->
    <query_thread_log>
        <database>system</database>
        <table>query_thread_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </query_thread_log>


    <!-- Metric log contains rows with current values of ProfileEvents, CurrentMetrics collected with "collect_interval_milliseconds" interval. -->
    <metric_log>
        <database>system</database>
        <table>metric_log</table>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <collect_interval_milliseconds>1000</collect_interval_milliseconds>
    </metric_log>
    <dictionaries_config>*_dictionary.xml</dictionaries_config>

    <!-- Uncomment if you want data to be compressed 30-100% better.
                  Don't do that if you just started using ClickHouse.
      -->
    <compression incl="clickhouse_compression">
    </compression>

    <!-- Allow to execute distributed DDL queries (CREATE, DROP, ALTER, RENAME) on cluster.
                  Works only if ZooKeeper is enabled. Comment it if such functionality isn't required. -->
    <distributed_ddl>
        <!-- Path in ZooKeeper to queue with DDL queries -->
        <path>/clickhouse/task_queue/ddl</path>

        <!-- Settings from this profile will be used to execute DDL queries -->
        <!-- <profile>default</profile> -->
    </distributed_ddl>

    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>

</yandex>
