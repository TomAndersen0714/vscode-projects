待办事项:
    1. 针对数据同步的所有任务, WTSS命名规范, 修改WTSS工作流下游依赖的节点, 其依赖的配置同样需要更名
    2. 针对数据 export 同步的 Spark Job, 抽离 partitionNum, batchSize, 通过参数配置
    3. 针对资源超额申请的 Spark Job, 通过 WTSS command 命令行设置 spark.executor 参数, 限制CPU开销
        Q: 此类型参数的调优, 是否应该去采集整个WTSS项目的 Spark Job 任务开销, 然后再去进行调优? 仅针对数据同步任务, 进行优化, 效果似乎比较有限
    4. 针对通过封装Sqoop.py脚本进行调用的任务, 抽离配置, 统一客户端
    5. 针对同时包含ETL和数据同步的任务, 拆分 ETL 任务和数据同步任务
        Q: 拆分之后, ETL 任务部分, 我理解就必须得落表了, 这样的话维护成本

规范化:
    1. 针对数据同步的所有任务, WTSS命名规范, 修改WTSS工作流下游依赖的节点, 其依赖的配置同样需要更名
    2. 针对通过封装 Sqoop.py 脚本进行调用的任务, 抽离配置生成配置文件, 统一客户端
    3. 针对同时包含 Transform 和数据同步的任务, 拆分 Transform 任务和数据同步任务
        Q: 拆分之后, Transform 任务的输出, 我理解就必须得落表了, 这样的话维护成本就上去了, 如何把握尺度, 是仅针对有JOIN的Transform 任务吗?
性能调优:
    1. 针对数据 export 同步的 Spark Job, 抽离 partitionNum, batchSize 并参数化, 通过配置控制参数值
    2. 针对资源超额申请的 Spark Job, 通过 WTSS command 命令行设置 spark.executor 参数, 限制CPU开销
        Q: 此类型参数的调优, 是否应该去采集整个WTSS项目的 Spark Job 任务开销, 然后再去进行调优? 仅针对数据同步任务, 进行优化, 效果似乎比较有限?