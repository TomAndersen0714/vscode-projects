# flume2:此配置用于将来自指定Avro端口的数据输出到HDFS中
# a2:Avro Source->Memory Channel->HDFS Sink

# Agent
a2.sources = r1
a2.channels = c1
a2.sinks = k1

# Sources
# 配置a2.sources.r1
a2.sources.r1.type = avro
# 设置监听本地IP
a2.sources.r1.bind = 0.0.0.0
# 设置监听端口号
a2.sources.r1.port = 4141

# Channels
# 配置a2.channels.c1
# 使用内存作为缓存/最多缓存的Event个数/单次传输的Event个数
a2.channels.c1.type = memory
a2.channels.c1.capacity = 1000
a2.channels.c1.transactionCapacity = 100

# Sinks
# 配置a2.sinks.k1
a2.sinks.k1.type = hdfs
# 定义a2的sinks.k2的类型为hdfs,即输出到hdfs目录下
a2.sinks.k1.type = hdfs
# 设置hdfs文件路径,同时并设置了按照日期创建文件夹
a2.sinks.k1.hdfs.path = /flume/group/logs/%Y-%m-%d/%H-%M-%S
# 设置flume创建的hdfs文件前缀
a2.sinks.k1.hdfs.filePrefix = logs-

# 以下三组参数的配置用于控制flume在hdfs中生成文件的滚动方式
# 满足以下三者中任何一个条件都会新生成hdfs文件
# 设置文件滚动的时间间隔,单位(second),置0表示关闭
a2.sinks.k1.hdfs.rollInterval = 10
# 设置文件滚动的最大size阈值,由于是hdfs sink故最好设置成Block Size的倍数
# 本次实验的hadoop版本为2.7.7(2.7.3之后默认Block Size为128MB,之前为64MB)
# 单位(bytes),置0表示关闭
a2.sinks.k1.hdfs.rollSize = 134217700
# 设置滚动文件存储的最大Event个数
# 此参数一般设置为0,即关闭,除非有严格生产需求并且知道Event大小能够自主控制
a2.sinks.k1.hdfs.rollCount = 0

# 设置flume每批次刷到hdfs中的Event个数(超过一定时长也会进行刷新,并非要等满一批次)
a2.sinks.k1.hdfs.batchSize = 100

# 设置hdfs文件格式,目前只支持(SequenceFile/DataStream/CompressedStream)
# 其中CompressedStream类型需要配合hdfs.codeC参数来指定具体的压缩方式
# SequenceFile表示按照序列文件的方式进行压缩,而DataStream则表示不进行压缩
a2.sinks.k1.hdfs.fileType = DataStream

# 以下三组参数的配置配合转义序列(如%Y %m %d %H %M %S等)能够自定义时间轮转最小刻度
# 设置hdfs时间向下取整
# 设置向下取整之后文件夹将按照30s的刻度进行创建文件夹
# 否则都是按照之前设置每秒进行文件夹的创建
a2.sinks.k1.hdfs.round = true
# 设置hdfs时间向下取整的最小单元倍数
a2.sinks.k1.hdfs.roundValue = 30
# 设置hdfs时间向下取整的最小单位
a2.sinks.k1.hdfs.roundUnit = second

# 设定是否使用本地时间戳,默认为false,即默认使用Event的Header中的时间戳
# 但本次实验中Event-Header为空,所以使用本地时间戳
a2.sinks.k1.hdfs.useLocalTimeStamp = true

# Bind
a2.sources.r1.channels = c1
a2.sinks.k1.channel = c1

