# 用于监听某个目录内所有文件Spooling Directory Source
# 每次未处理的文件都会通过memory channel传输最后输出到hdfs sinks

# 定义Agent三大件
a3.sources = r1
a3.sinks = k1
a3.channels = c1

# 配置Spooling Directory Sources
a3.sources.r1.type = spooldir
# 设置监控的文件目录
a3.sources.r1.spoolDir = /tmp/logs
# 设置对搜集完成的本地文件添加后缀,表示此文件已经被处理过
# 注意后缀名是flume判断此文件是否被处理过的唯一标识,所以此后缀名必须确保无其他文件使用
# 否则将不会处理同后缀名文件
a3.sources.r1.fileSuffix = .COMPLETED
# 设置是否使用文件绝对路径充当Event的Header
a3.sources.r1.fileHeader = true


# 配置HDFS Sinks
# 定义a2的sinks.k2的类型为hdfs,即输出到hdfs目录下
a3.sinks.k1.type = hdfs
# 设置hdfs文件路径,同时并设置了按照日期创建文件夹
a3.sinks.k1.hdfs.path = /flume/logs/%Y-%m-%d/%H-%M-%S
# 设置flume创建的hdfs文件前缀
a3.sinks.k1.hdfs.filePrefix = logs-

# 以下三组参数的配置用于控制flume在hdfs中生成文件的滚动方式
# 满足以下三者中任何一个条件都会新生成hdfs文件
# 设置文件滚动的时间间隔,单位(second),置0表示关闭
a3.sinks.k1.hdfs.rollInterval = 10
# 设置文件滚动的最大size阈值,由于是hdfs sink故最好设置成Block Size的倍数
# 本次实验的hadoop版本为2.7.7(2.7.3之后默认Block Size为128MB,之前为64MB)
# 单位(bytes),置0表示关闭
a3.sinks.k1.hdfs.rollSize = 134217700
# 设置滚动文件存储的最大Event个数
# 此参数一般设置为0,即关闭,除非有严格生产需求并且知道Event大小能够自主控制
a3.sinks.k1.hdfs.rollCount = 0

# 设置flume每批次刷到hdfs中的Event个数(超过一定时长也会进行刷新,并非要等满一批次)
a3.sinks.k1.hdfs.batchSize = 100

# 设置hdfs文件格式,目前只支持(SequenceFile/DataStream/CompressedStream)
# 其中CompressedStream类型需要配合hdfs.codeC参数来指定具体的压缩方式
# SequenceFile表示按照序列文件的方式进行压缩,而DataStream则表示不进行压缩
a3.sinks.k1.hdfs.fileType = DataStream

# 以下三组参数的配置配合转义序列(如%y %m %d %H %M %S等)能够自定义时间轮转最小刻度
# 设置hdfs时间向下取整
# 设置向下取整之后文件夹将按照一定时间大小的刻度进行创建文件夹
# 否则都是按照之前设置每分钟进行文件夹的创建
a3.sinks.k1.hdfs.round = true
# 设置hdfs时间向下取整的最小单元倍数
a3.sinks.k1.hdfs.roundValue = 30
# 设置hdfs时间向下取整的最小单位
a3.sinks.k1.hdfs.roundUnit = second

# 设定是否使用本地时间戳,默认为false,即使用Event的Header中的时间戳,但本次实验中Event-Header为空
a3.sinks.k1.hdfs.useLocalTimeStamp = true


# 配置Memory Channels
# 定义a2的channerls.c1的类型为memory,即使用内存作为缓存/最多缓存的Event个数/单次传输的Event个数
a3.channels.c1.type = memory
a3.channels.c1.capacity = 1000
a3.channels.c1.transactionCapacity = 100


# 绑定Sources/Sinks到Channels上
# 注意:source可以绑定多个channel,但是sink只能绑定单个channel
a3.sources.r1.channels = c1
a3.sinks.k1.channel = c1
