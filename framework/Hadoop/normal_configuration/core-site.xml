<configuration>

    <!--指定HDFS文件系统访问地址,将其设置为NameNode的地址,并指定通信端口-->
    <!-- 默认值:file:/// -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop101:9000</value>
        <description>The name of the default file system.</description>
    </property>

    <!--指定Hadoop运行时产生的临时文件存储目录-->
    <!-- 默认值:/tmp/hadoop-${user.name} -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-2.7.7/tmp</value>
        <description>A base for other temporary directories.</description>
    </property>

    <!-- 指定http访问Web UI页面时的默认用户,此处为超级用户tomandersen,便于直接访问个人集群的HDFS Web -->
    <!-- 启动NameNode的用户即为超级用户,并不固定,需要根据实际情况修改 -->
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>tomandersen</value>
    </property>

    <!-- 使用超级用户tomandersen模拟所有用户执行MR job -->
    <!-- 此超级用户需要根据实际情况更改,例如:当时配置hadoop和启动hadoop的用户为hadoop,则
        所有tomandersen的字眼都要改成hadoop
     -->
    <property>
        <name>hadoop.proxyuser.tomandersen.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.tomandersen.groups</name>
        <value>*</value>
    </property>

    <!-- 声明可用的压缩算法的编/解码器 -->
    <property>
        <name>io.compression.codecs</name>
        <value>
            org.apache.hadoop.io.compress.GzipCodec,
            org.apache.hadoop.io.compress.DefaultCodec,
            org.apache.hadoop.io.compress.DeflateCodec,
            org.apache.hadoop.io.compress.BZip2Codec,
            org.apache.hadoop.io.compress.SnappyCodec,
            org.apache.hadoop.io.compress.Lz4Codec,
            com.hadoop.compression.lzo.LzoCodec,
            com.hadoop.compression.lzo.LzopCodec
        </value>
        <description>
            A comma-separated list of the compression codec classes that can
            be used for compression/decompression. In addition to any classes specified
            with this property (which take precedence), codec classes on the classpath
            are discovered using a Java ServiceLoader.
        </description>
    </property>

    <!-- 配置lzo编解码器相关参数 -->
    <property>
        <name>io.compression.codec.lzo.class</name>
        <value>com.hadoop.compression.lzo.LzoCodec</value>
    </property>

</configuration>